{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "adba3aa9-4ec4-4d75-9034-a5442f329266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in d:\\anaconda\\anacondaprojects\\lib\\site-packages (0.11.4)\n",
      "Requirement already satisfied: openai in d:\\anaconda\\anacondaprojects\\lib\\site-packages (1.58.1)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\anacondaprojects\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber openai\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1b7033d6-8788-4389-ae5a-c1ae2fac328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.58.1\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: \n",
      "Location: D:\\Anaconda\\anacondaprojects\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b579b229-19db-48f7-8f7e-e5c5476a6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import openai\n",
    "\n",
    "# Function to extract text and tables from a specific page in the PDF\n",
    "def extract_text_and_tables(pdf_path, page_number):\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            if page_number < 0 or page_number >= len(pdf.pages):  # Check if page exists\n",
    "                return None, None  # Return None if the page number is out of range\n",
    "            \n",
    "            page = pdf.pages[page_number]\n",
    "            text = page.extract_text()  # Extract text from the page\n",
    "            tables = page.extract_tables()  # Extract tables from the page\n",
    "            \n",
    "            return text, tables\n",
    "    except Exception as e:\n",
    "        return str(e), None\n",
    "\n",
    "# Function to handle user query and interact with the LLM\n",
    "def query_llm(text, query):\n",
    "    try:\n",
    "        # Call the new API method using the OpenAI Chat API (models like gpt-3.5 or gpt-4)\n",
    "        response = openai.Completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # You can change this to another model like \"gpt-4\" if needed\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Based on the following text, {query}:\\n\\n{text}\"}\n",
    "            ],\n",
    "            max_tokens=200,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        return response['choices'][0]['message']['content'].strip()  # Return the processed response\n",
    "    except Exception as e:\n",
    "        return f\"Error querying LLM: {str(e)}\"\n",
    "\n",
    "\n",
    "# Function to handle the query logic\n",
    "def handle_query(user_query, pdf_path):\n",
    "    try:\n",
    "        # Extract the page number from the query (assuming format like 'page 2')\n",
    "        if \"page\" in user_query.lower():\n",
    "            page_number = int(user_query.split(\"page\")[1].split()[0]) - 1  # Convert to 0-based index\n",
    "        else:\n",
    "            return \"Invalid query format. Please specify a page number.\"\n",
    "\n",
    "        # Extract text and tables from the PDF page\n",
    "        page_text, tables = extract_text_and_tables(pdf_path, page_number)\n",
    "        \n",
    "        if page_text is None:\n",
    "            return f\"The specified page {page_number + 1} does not exist in the PDF.\"\n",
    "        \n",
    "        # Process the extracted text with the LLM based on user query\n",
    "        response = f\"Data from page {page_number + 1}:\\n\\n\"\n",
    "        response += f\"Text:\\n{page_text}\\n\\n\" if page_text else \"No text found on this page.\\n\\n\"\n",
    "        \n",
    "        # If tables are found, add them to the response\n",
    "        if tables:\n",
    "            response += \"Tables found on this page:\\n\"\n",
    "            for i, table in enumerate(tables):\n",
    "                response += f\"\\nTable {i + 1}:\\n\"\n",
    "                for row in table:\n",
    "                    response += \" | \".join(str(cell) for cell in row) + \"\\n\"\n",
    "        else:\n",
    "            response += \"No tables found on this page.\"\n",
    "\n",
    "        # Use LLM to extract specific information based on the query\n",
    "        llm_response = query_llm(page_text, user_query)\n",
    "        response += f\"\\nLLM Response:\\n{llm_response}\"\n",
    "\n",
    "        return response\n",
    "\n",
    "    except (IndexError, ValueError):\n",
    "        return \"Invalid query format. Please specify a valid page number.\"\n",
    "\n",
    "# Main block to run the program\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your OpenAI API key\n",
    "    openai.api_key = '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'  # Make sure to replace this with your actual API key\n",
    "    \n",
    "    # PDF file path\n",
    "    pdf_path = r\"C:\\Users\\DELL\\Downloads\\Tables- Charts- and Graphs with Examples from History- Economics- Education- Psychology- Urban Affairs and Everyday Life - 2017-2018.pdf\"\n",
    " # Replace with the actual path to your PDF\n",
    "\n",
    "    # User input query\n",
    "    user_query = input(\"Enter your query: \")\n",
    "\n",
    "    # Get response based on the query\n",
    "    response = handle_query(user_query, pdf_path)\n",
    "\n",
    "    # Print the response\n",
    "    print(response)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "   \n",
    "  \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081ab9b-52c9-40d5-abb5-4166d217cf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
